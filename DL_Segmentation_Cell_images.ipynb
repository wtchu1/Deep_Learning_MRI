{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DL_Segmentation_Cell_images.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23iz2gyKaToc"
      },
      "source": [
        "# Autonomous segmentation of nuclei\n",
        "This task was produced by Kaggle for the 2018 Data Science Bowl and instructed researchers to segment a wide range of nuclei across varied conditions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w5byjuYaToh",
        "outputId": "71276cfe-1742-4b4a-dd85-08be4d011b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ------ Download & reorganize data -------\n",
        "import os\n",
        "# Data download and unzipping\n",
        "!wget –quiet  https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_test.zip -c\n",
        "!wget –quiet  https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_train.zip -c\n",
        "\n",
        "# Place data into train and test folders\n",
        "if os.path.isdir('stage1_train'):\n",
        "  !rm -rf 'stage1_train'\n",
        "  \n",
        "if os.path.isdir('stage1_test'):\n",
        "  !rm -rf 'stage1_test'\n",
        "  \n",
        "!mkdir stage1_train stage1_test\n",
        "\n",
        "!unzip -qq stage1_train.zip -d stage1_train/\n",
        "!unzip -qq stage1_test.zip -d stage1_test/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-28 22:34:16--  http://xn--quiet-xu3b/\n",
            "Resolving xn--quiet-xu3b (xn--quiet-xu3b)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘xn--quiet-xu3b’\n",
            "--2021-02-28 22:34:16--  https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2021-02-28 22:34:16--  http://xn--quiet-xu3b/\n",
            "Resolving xn--quiet-xu3b (xn--quiet-xu3b)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘xn--quiet-xu3b’\n",
            "--2021-02-28 22:34:16--  https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_train.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k6_MsjNaTok"
      },
      "source": [
        "# Downloading and installing keras\n",
        "!pip -q install keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlj37groaTok"
      },
      "source": [
        "# Import packages\n",
        "import random #for seeds\n",
        "# for system\n",
        "import sys\n",
        "import warnings\n",
        "# structures for storing the data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "# Image processing tools\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "# Deep learning tools\n",
        "from keras.utils import Progbar\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Convolution2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras import backend as K\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "\n",
        "# Setting seed for reproducability\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "smooth = 1.\n",
        "epochs = 50"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZogI-ea0QH"
      },
      "source": [
        "# Data Path\r\n",
        "TRAIN_PATH = 'stage1_train/'\r\n",
        "TEST_PATH = 'stage1_test/'\r\n",
        "\r\n",
        "# Get train and test IDs\r\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1]\r\n",
        "test_ids = next(os.walk(TEST_PATH))[1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLCLXyqaaTom"
      },
      "source": [
        "# Function read train images and mask return as nump array\r\n",
        "def read_train_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\r\n",
        "    # Initialize arrays for images and masks\r\n",
        "    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\r\n",
        "    Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\r\n",
        "    print('Getting and resizing train images and masks ... ')\r\n",
        "\r\n",
        "    # Load data into arrays from memory\r\n",
        "    sys.stdout.flush() # ?\r\n",
        "    if os.path.isfile(\"train_img.npy\") and os.path.isfile(\"train_mask.npy\"):\r\n",
        "        print(\"Train file loaded from memory\")\r\n",
        "        X_train = np.load(\"train_img.npy\")\r\n",
        "        Y_train = np.load(\"train_mask.npy\")\r\n",
        "        return X_train,Y_train\r\n",
        "    \r\n",
        "    # if the train data is not already in memory\r\n",
        "    a = Progbar(len(train_ids))\r\n",
        "    for n, id_ in enumerate(train_ids):\r\n",
        "        path = TRAIN_PATH + id_\r\n",
        "        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\r\n",
        "        # Resample image to common dimensions\r\n",
        "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\r\n",
        "        # Fill array with image\r\n",
        "        X_train[n] = img\r\n",
        "        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\r\n",
        "        for mask_file in next(os.walk(path + '/masks/'))[2]:\r\n",
        "            mask_ = imread(path + '/masks/' + mask_file)\r\n",
        "            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \r\n",
        "                                        preserve_range=True), axis=-1)\r\n",
        "            mask = np.maximum(mask, mask_)\r\n",
        "        Y_train[n] = mask\r\n",
        "        a.update(n+1)\r\n",
        "    np.save(\"train_img\",X_train)\r\n",
        "    np.save(\"train_mask\",Y_train)\r\n",
        "    return X_train,Y_train"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_CNIuQVJbZ4"
      },
      "source": [
        "# Function to read test images and return as numpy array\r\n",
        "def read_test_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\r\n",
        "    X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\r\n",
        "    sizes_test = []\r\n",
        "    print('\\nGetting and resizing test images ... ')\r\n",
        "    sys.stdout.flush()\r\n",
        "    # Load test data from memory\r\n",
        "    if os.path.isfile(\"test_img.npy\") and os.path.isfile(\"test_size.npy\"):\r\n",
        "        print(\"Test file loaded from memory\")\r\n",
        "        X_test = np.load(\"test_img.npy\")\r\n",
        "        sizes_test = np.load(\"test_size.npy\")\r\n",
        "        return X_test,sizes_test\r\n",
        "\r\n",
        "    # Get data from files and load into memory\r\n",
        "    b = Progbar(len(test_ids))\r\n",
        "    for n, id_ in enumerate(test_ids):\r\n",
        "        path = TEST_PATH + id_\r\n",
        "        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\r\n",
        "        sizes_test.append([img.shape[0], img.shape[1]])\r\n",
        "        # resample images\r\n",
        "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\r\n",
        "        X_test[n] = img\r\n",
        "        b.update(n+1)\r\n",
        "    np.save(\"test_img\",X_test)\r\n",
        "    np.save(\"test_size\",sizes_test)\r\n",
        "    return X_test,sizes_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52hbXukiaTom"
      },
      "source": [
        "# Metric function\r\n",
        "def dice_coef(y_true, y_pred):\r\n",
        "    # Calculate dice coefficient based on true and predicted mask\r\n",
        "    y_true_f = K.flatten(y_true)\r\n",
        "    y_pred_f = K.flatten(y_pred)\r\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\r\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\r\n",
        "def dice_coef_loss(y_true, y_pred):\r\n",
        "    # the loss function is the negative dice coefficient\r\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEeRBMHOtKwY"
      },
      "source": [
        "def get_unet(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\r\n",
        "    # Create the unet model\r\n",
        "    # Add each layer to the model\r\n",
        "    \"\"\"\r\n",
        "    Types of layers\r\n",
        "      Conv2D(<n filters>, <kernel size>, ...) - 2D convolutional layer\r\n",
        "      Dropout(<rate>) -  randomly sets input units to 0 with a frequency of rate at \r\n",
        "        each step during training time, which helps prevent overfitting\r\n",
        "      MaxPooling2D()\r\n",
        "      Conv2DTranspose(<filters>, <kernel size>, ...)- 2D deconvolution layer\r\n",
        "      concatenate\r\n",
        "    Activation functions\r\n",
        "      https://keras.io/api/layers/activations/\r\n",
        "      elu - Exponential linear unit, kinda like relu except x<0 is a log func\r\n",
        "      sigmoid - looks like an s\r\n",
        "    kernal initializer\r\n",
        "      https://keras.io/api/layers/initializers/\r\n",
        "      he_normal - draws samples from a truncated normal distribution centered on 0\r\n",
        "    padding\r\n",
        "      valid - No padding\r\n",
        "      same - padding evenly to the left/right or up/down of the input\r\n",
        "        such that output has the same height/width dimension as the input\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\r\n",
        "    s = Lambda(lambda x: x / 255) (inputs)\r\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\r\n",
        "    c1 = Dropout(0.1) (c1)\r\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\r\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\r\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\r\n",
        "    c2 = Dropout(0.1) (c2)\r\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\r\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\r\n",
        "\r\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\r\n",
        "    c3 = Dropout(0.2) (c3)\r\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\r\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\r\n",
        "\r\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\r\n",
        "    c4 = Dropout(0.2) (c4)\r\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\r\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\r\n",
        "\r\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\r\n",
        "    c5 = Dropout(0.3) (c5)\r\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\r\n",
        "\r\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\r\n",
        "    u6 = concatenate([u6, c4])\r\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\r\n",
        "    c6 = Dropout(0.2) (c6)\r\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\r\n",
        "\r\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\r\n",
        "    u7 = concatenate([u7, c3])\r\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\r\n",
        "    c7 = Dropout(0.2) (c7)\r\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\r\n",
        "\r\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\r\n",
        "    u8 = concatenate([u8, c2])\r\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\r\n",
        "    c8 = Dropout(0.1) (c8)\r\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\r\n",
        "\r\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\r\n",
        "    u9 = concatenate([u9, c1], axis=3)\r\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\r\n",
        "    c9 = Dropout(0.1) (c9)\r\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\r\n",
        "\r\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\r\n",
        "\r\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\r\n",
        "    model.compile(optimizer='adam',loss='binary_crossentropy', metrics=[dice_coef])\r\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaK29iIcxcNX",
        "outputId": "c489cf42-98d5-438d-ece2-ae7f68eecc41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# get train_data\r\n",
        "train_img,train_mask = read_train_data()\r\n",
        "\r\n",
        "# get test_data\r\n",
        "test_img,test_img_sizes = read_test_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting and resizing train images and masks ... \n",
            "670/670 [==============================] - 391s 582ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9ea39a4f5150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get test_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_img_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'read_test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhyYBbsXxhQd"
      },
      "source": [
        "u_net = get_unet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V48cUd-axjlC"
      },
      "source": [
        "import keras\r\n",
        "stop_early = keras.callbacks.EarlyStopping(monitor='val_dice_coef',\r\n",
        "                                           patience=8,\r\n",
        "                                           mode='max')\r\n",
        "#set max number of epochs\r\n",
        "epochs=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzdYk4-fxoOd"
      },
      "source": [
        "# fit model on train_data\r\n",
        "print(\"\\nTraining...\")\r\n",
        "history=u_net.fit(train_img,train_mask,\r\n",
        "                  validation_split=0.15,\r\n",
        "                  batch_size=16,\r\n",
        "                  epochs=epochs,\r\n",
        "                  callbacks=[stop_early])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}